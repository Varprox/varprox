\section{Introduction}

% ---------------------------------------------------------------------------- %

\subsection{Contributions}

% ---------------------------------------------------------------------------- %

\subsection{Previous studies / State-of-the-art}
\label{ssec:prev_stud}

\cite{Leeuwen_T_2021_j-siam-j-sci-comput_variable_pnp}: does not handle box
constraint with regularization. In contrast, we can do it using primal-dual
optimization.

% ---------------------------------------------------------------------------- %

\subsection{Organization of the paper}

% ---------------------------------------------------------------------------- %

\subsection{Notation}

% ============================================================================ %

\section{}

% ============================================================================ %

\section{}

\begin{equation}
  \label{eq:optim_pb}
  \begin{aligned}
    \min_{\bbeta,\btau} \quad &
    \frac{1}{2} \sum_{n=1}^{N} {\left(F_{n}(\bbeta)\btau - \tilde{w}_{n}\right)}^{2}
    +\frac{1}{2}\lambda_{\alpha}\norm{\btau}_{2}^{2} + \lambda_{\beta}\mR(\bbeta) \\
    \textrm{s.t.} \quad &
    \btau \in \RR^{M}_{+} \, , \, \bbeta \in ]0,1[^{M} \, .
  \end{aligned}
\end{equation}
where $\mR$ is a regularization that is proper, convex and lower-semicontinuous.
For instance, $\mR$ can be the total variation (TV) $\mR(\*x)=\norm{\*D\*x}_{1}$
with $\*D$ the discrete gradient matrix defined as the idendity matrix with
coefficients -1 on its subdiagonal.

Equation~\eqref{eq:optim_pb} has the typical form of a constrained variable
projection problem~\cite{Golub_G_2003_j-inv-prob_separable_nlsvpma}.
Indeed, it can be formulated as
\begin{equation}
  \begin{aligned}
    \min_{\bbeta,\btau} \quad &
    \frac{1}{2} \norm{\begin{pmatrix}\*F(\bbeta) \\ \sqrt{\lambda_{\alpha}}\Id\end{pmatrix}\btau
        - \begin{pmatrix}\bwtilde\\ \*0 \end{pmatrix}}_{2}^{2}
    + \lambda_{\beta}\mR(\bbeta) \\
    \textrm{s.t.} \quad &
    \btau \in \RR^{M}_{+} \, , \, \bbeta \in ]0,1[^{M} \, .
  \end{aligned}
\end{equation}

Solving Problem~\ref{eq:optim_pb} can be performed in a block-descent scheme.
Minimization with respect to $\btau$ consists in solving a non-negative
least-squares problem.
This problem can be solved using for instance trust region reflective algorithm
described in~\cite{Coleman_T_1996_j-siam-j-optim_interior_tranmsb} and implemented
in SciPy library~\cite{Virtanen_P_2020_j-nat-meth_scipy_fascp}.
Minimization with respect to $\bbeta$ can be performed with primal-dual
methods~\cite{Komodakis_N_2015_j-ieee-sig-proc-mag_playing_d}.
Indeed, setting $f$ as the indicator function of the set $[\epsilon, 1-\epsilon]$, $g$ as
the $\ell_{1}$-norm multiplied by $\lambda_{\beta}$, and $h$ as the least-squares term,
Problem~\ref{eq:optim_pb} can be written as an unconstrained problem of
the form
\begin{equation}
  \label{eq:uncons_beta_optim}
  \min_{\bbeta\in\mathbb{R}^{M}} f(\bbeta) + g(\*D\bbeta) + h(\bbeta) \, ,
\end{equation}
where $f$, $g$, and $h$ are proper, convex, and lower-semicontinuous functions,
$h$ is gradient $1$-Lipschitz, and $D$ is a linear operator from $\RR^{M}$ to
$\RR^{M}$.
The dual problem of~\eqref{eq:uncons_beta_optim} is hence given by
\begin{equation}
  \label{eq:dual_beta_optim}
  \min_{\*v\in\mathbb{R}^{M}} (f^{*} \iconv h^{*})(\*L^{\top}\*v) + g^{*}(\*v) \, ,
\end{equation}
where $\*v$ is the dual variable, ${}^{*}$ denotes the Fenchel transform such
that $f^{*}(\*v)=\sup_{\*x\in\RR^{M}}(\scalar{\*x}{\*v}-f(\*x))$, and
$\iconv$ is the infinimal convolution defined by
$(f \iconv g)(\*x) = \inf_{\*y\in\RR^{M}} f(\*y) + g(\*x-\*y)$.
Note that the infinimal convolution acts to the Fenchel transform as the classic
convolution to the Fourier transform~\cite{Komodakis_N_2015_j-ieee-sig-proc-mag_playing_d}.
For instance, the two following equalities hold:
${(f \iconv g)}^{*} = f^{*} + g^{*}$ and ${(f+g)}^{*} = f^{*} \iconv g^{*}$.
The main idea of primal-dual algorithms consists then to solve both the
primal~\eqref{eq:uncons_beta_optim} and the dual~\eqref{eq:dual_beta_optim}
problems at the same time.
A parallel to solving signal processing problems using time-frequency approach
can be made.
Exploiting information of both problems allows primal-dual techniques to yield
computational advantages as well as to tackle more general problems.

In order to solve Problem~\eqref{eq:uncons_beta_optim} (and
consequently~\eqref{eq:dual_beta_optim}), we propose to use the Rescaled Primal
Dual Forward-Backward (RFBPD)~\cite{Komodakis_N_2015_j-ieee-sig-proc-mag_playing_d}
whose iteration scheme is displayed in Equation~\eqref{eq:rfbpd}
\begin{equation}
  \label{eq:rfbpd}
  \begin{aligned}
    \*p_{n} &= \textrm{prox}_{\rho f} (\bbeta_{n}-\rho(\nabla h(\bbeta_{n})+\sigma \*D^{\top}\*v_{n})) \\
    \*q_{n} &= (\mathrm{Id}-\textrm{prox}_{\lambda g/\sigma}) (\*v_{n}+\*D(2\*p_{n}-\bbeta_{n})) \\
    (\*\bbeta_{n+1},\*v_{n+1}) &= (\bbeta_{n},\*v_{n}) + \omega_{n}((\*p_{n},\*q_{n})-(\bbeta_{n},\*v_{n}))
    \, ,
  \end{aligned}
\end{equation}
where $\omega$ is a positive relaxation or inertial factor, and $\tau$ and $\sigma$ are the
two step-sizes.
Noting that $\mathrm{Id}-\textrm{prox}_{\lambda g/\sigma}$ is, up to a rescaling, equal to
$\prox_{\sigma g^{*}}$, the iteration~\eqref{eq:rfbpd} closely looks like a
Forward-Backward (FB) step performs on the primal, followed by a FB step
performs on the dual.

The implementation of the RFBPD algorithm to solve~\eqref{eq:optim_pb} is given
in Algorithm~\ref{algo:rfbpd} where $\Soft_{\gamma}$ is the soft thresholding operator
with positive parameter $\gamma$ applied element-wise
$\Soft_{\gamma}(x) = \sgn(x)\max(0,\abs{x}-\gamma)$.
%% Thanks to the primal dual approach, we can separate the operator $\*D$ and the
%% $\ell_{1}$ in the computation of the proximal operator of the TV regularization and we
%% obtain a closed form expression.

\begin{algorithm}[t]
  \small
  \begin{algorithmic}[1]
    \renewcommand{\algorithmicrequire}{\textbf{Input:}}
    \renewcommand{\algorithmicensure}{\textbf{Output:}}
    \REQUIRE{Initial value of $\bbeta_{0}$}
    \REQUIRE{$(\tau,\sigma)\in]0,+\infty[^{2}$, and $\omega\in\RR_{+}$.}
    \ENSURE{Estimate of $\bbeta$.}
    \STATE{Initialize $i$ to $0$.}
    \STATE{Initialize $\*v$ to $\*0$.}
    \REPEAT{}
    \STATE{Primal update:
      \[
      \begin{aligned}
        \*p &= \bbeta - \tau\nabla g(\bbeta) - \sigma \*D^{\top}\*v \\
        \*p &= \Pi_{[\epsilon,1-\epsilon]^{M}}(\*p)
      \end{aligned}
      \]}
    \STATE{Dual update:
      \[
      \*q = (\Id - \Soft_{\lambda_{\beta}/\sigma})(\*v+\*S(2\*p-\bbeta))
      \]}
    \STATE{Inertial update:
      \[
      \begin{aligned}
        \bbeta &= \bbeta + \omega(\*p-\bbeta) \\
        \*v &= \*v + \omega(\*q - \*v)
      \end{aligned}
      \]}
    \STATE{Increment $i$.}
    \UNTIL{stopping criterion is met}
    \RETURN{$\bbeta$}
  \end{algorithmic}
  \caption{Implementation of RFBPD to solve~\eqref{eq:optim_pb} in
    $\bbeta$~\label{algo:rfbpd}}
\end{algorithm}

% ============================================================================ %

\section{}

% ============================================================================ %

\section{Conclusion}
\label{sec:concl}

Conclusion
